{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89581b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.pipeline import make_pipeline  \n",
    "from sklearn.metrics import accuracy_score  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Embedding, SimpleRNN, LSTM, Dense  \n",
    "from keras.callbacks import EarlyStopping  \n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  \n",
    "\n",
    "from nltk.tokenize import word_tokenize  \n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.stem import PorterStemmer  \n",
    "import nltk  \n",
    "\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory  \n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory  \n",
    "\n",
    "from google_play_scraper import app, reviews, Sort, reviews_all  \n",
    "\n",
    "from wordcloud import WordCloud  \n",
    "from textblob import TextBlob  \n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "import datetime as dt  \n",
    "import re  \n",
    "import string  \n",
    "\n",
    "# Pengaturan opsional\n",
    "pd.options.mode.chained_assignment = None  \n",
    "np.random.seed(0)  \n",
    "\n",
    "# Unduh resource NLTK\n",
    "nltk.download('punkt')  \n",
    "nltk.download('stopwords')  \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengimpor pustaka google_play_scraper untuk mengakses ulasan dan informasi aplikasi dari Google Play Store.  \n",
    "from google_play_scraper import app, reviews_all, Sort  \n",
    "import csv  \n",
    "\n",
    "# Mengambil semua ulasan dari aplikasi dengan ID 'com.twitter.android' di Google Play Store.  \n",
    "scrapreview = reviews_all(  \n",
    "    'com.twitter.android',         \n",
    "    lang='en',                     \n",
    "    country='us',                  \n",
    "    sort=Sort.MOST_RELEVANT,    \n",
    "    count=10000               \n",
    ")  \n",
    "\n",
    "# Batasi jumlah ulasan yang diambil ke 15.000  \n",
    "scrapreview = scrapreview[:15000]  \n",
    "\n",
    "# Menyimpan ulasan dalam file CSV  \n",
    "with open('ulasan_aplikasi.csv', mode='w', newline='', encoding='utf-8') as file:  \n",
    "    writer = csv.writer(file)  \n",
    "    writer.writerow(['Review']) \n",
    "    for review in scrapreview:  \n",
    "        writer.writerow([review['content']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be2c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_reviews_df = pd.DataFrame(scrapreview)\n",
    "app_reviews_df.shape\n",
    "app_reviews_df.head()\n",
    "app_reviews_df.to_csv('ulasan_aplikasi.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
